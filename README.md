# PEARL (Learning High-Quality and General-Purpose Phrase Representations)
:book: [paper](https://arxiv.org/pdf/2401.10407.pdf)  ðŸ¤— [PEARL-small](https://huggingface.co/Lihuchen/pearl_small) ðŸ¤— [PEARL-base](Lihuchen/pearl_base)

Our PEARL is a framework to learn phrase-level representations. <br>
If you require semantic similarity computation for strings, our PEARL model might be a helpful tool. <br>
It offers powerful embeddings suitable for tasks like string matching, entity retrieval, entity clustering, and fuzzy join. 

| Model |Size| PPDB | PPDB filtered |Turney|BIRD|YAGO|UMLS|CoNLL|BC5CDR|AutoFJ|Avg
|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|
| FastText  |-|  94.4  | 61.2  |  59.6  | 58.9  |16.9|14.5|3.0|0.2| 53.6|40.3|
| Sentence-BERT  |110M| 94.6  | 66.8  | 50.4  | 62.6  | 21.6|23.6|25.5|48.4| 57.2| 50.1|
| Phrase-BERT  |110M|  96.8  |  68.7  | 57.2  |  68.8  |23.7|26.1|35.4| 59.5|66.9| 54.5|
| E5-small  |34M|  96.0| 56.8|55.9| 63.1|43.3| 42.0|27.6| 53.7|74.8|57.0|
|E5-base|110M|  95.4|65.6|59.4|66.3| 47.3|44.0|32.0| 69.3|76.1|61.1|
|PEARL-small|34M|  97.0|70.2|57.9|68.1| 48.1|44.5|42.4|59.3|75.2|62.5|
|PEARL-base|110M|97.3|72.2|59.7|72.6|50.7|45.8|39.3|69.4|77.1|64.8|

| - | PPDB | PPDB filtered |Turney|BIRD|YAGO|UMLS|CoNLL|BC5CDR|AutoFJ|
|-|-|-|-|-|-|-|-|-|-|
|Task|Paraphrase Classification|Paraphrase Classification|Phrase Similarity|Phrase Similarity|Entity Retrieval|Entity Retrieval|Entity Clustering|Entity Clustering|Fuzzy Join|
|Metric|Acc|Acc|Acc|Pearson|Top-1 Acc|Top-1 Acc|NMI|NMI|Acc|

The repo structure is shown below. <br>
The `data` directory contains all data needed for training and evaluation. [data](https://www.dropbox.com/scl/fi/49c87s9tm8jgf3gwmcz0e/data.zip?rlkey=g47iv7oy5fgonj6obe2d8kiq1&dl=1) <br>
The `output` directory has our model (PEARL-small), and you can use it to reproduce the results reported in Table 1. [PEARL-small](https://www.dropbox.com/scl/fi/96nui29fj6wlj7roy6pl4/output.zip?rlkey=ra0lngk9afyokpqv9xcrptjyz&dl=1)
<br>
The `source` directory includes all the source code for our framework.
```
â”œâ”€â”€â”€data
â”‚   â”‚   autofj.md
â”‚   â”‚   bird.txt
â”‚   â”‚   freq_phrase.txt
â”‚   â”‚   hard_negative_test.txt
â”‚   â”‚   love_model.pt
â”‚   â”‚   phrase_aug_test.jsonl
â”‚   â”‚   phrase_with_etype.txt
â”‚   â”‚   ppdb.json
â”‚   â”‚   ppdb_filtered.json
â”‚   â”‚   token_aug_test.jsonl
â”‚   â”‚   turney.txt
â”‚   â”‚   vocab.txt
â”‚   â”‚
â”‚   â”œâ”€â”€â”€bc5cdr
â”‚   â”‚       test.json
â”‚   â”‚
â”‚   â”œâ”€â”€â”€conll2003
â”‚   â”‚       test.json
â”‚   â”‚
â”‚   â”œâ”€â”€â”€umls
â”‚   â”‚       umls_kb.txt
â”‚   â”‚       umls_test.txt
â”‚   â”‚
â”‚   â””â”€â”€â”€yago
â”‚           yago_kb.txt
â”‚           yago_test.txt
â”‚
â”œâ”€â”€â”€output
â””â”€â”€â”€source
    â”‚   augmentation.py
    â”‚   clean.py
    â”‚   evaluation.py
    â”‚   loader.py
    â”‚   loss.py
    â”‚   love_inference.py
    â”‚   love_model.py
    â”‚   main.py
    â”‚   model.py
    â”‚   registry.py
    â”‚   tokenization.py
    â”‚   utils.py
    â”‚   __init__.py
```
## Data Preparation
* All dataset and training corpus: [download](https://www.dropbox.com/scl/fi/49c87s9tm8jgf3gwmcz0e/data.zip?rlkey=g47iv7oy5fgonj6obe2d8kiq1&dl=1)
* [PEARL-small](https://www.dropbox.com/scl/fi/96nui29fj6wlj7roy6pl4/output.zip?rlkey=ra0lngk9afyokpqv9xcrptjyz&dl=1)

## Training
First, you can use `-help` to show the arguments
```python
python main.py -help
```
Once completing the data preparation and environment setup, we can train the model via `main.py`.
We have also provided sample datasets, you can just run the mode without downloading.
```python
python main.py -encoder pearl_small -dataset '../data/freq_phrase.txt'
```
## Reproduction
To show the experimental results in Table 1, you can use the following command and 
we have provided the trained model we used in our paper. 

```python
python run_eval.py

## expected output
model parametersï¼š~40M
bird_score = 0.6983
turney_score = 0.5623
conll_nmi = 0.4829
bc5cdr_nmi = 0.6240
ppdb_acc = 0.9745
ppdb_filtered_acc = 0.6876
autofj_acc = 0.7471
yago_acc = 0.4813
umls_acc = 0.4347

```


